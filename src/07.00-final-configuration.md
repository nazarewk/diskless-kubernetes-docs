
# Docelowa konfiguracja w sieci uczelnianej

Pełną konfiguracja `k8s` można uruchomić z maszyny ldap; znajduje się ona w
folderze `/pub/Linux/CoreOS/zetis/kubernetes` maszyny `ldap`, który zawiera
podane foldery:

- `kubernetes-cluster` - moje repozytorium zawierające konfigurację i skrypty
  pozwalające uruchomić klaster,
- `boot` - skrót do folderu `kubernetes-cluster/zetis/WWW/boot` zawierającego
  konfigurację iPXE oraz Ignition:
  - `coreos.ign` - plik konfigurujący CoreOS, wygenerowany z pliku `coreos.yml`
    narzędziem do transpilacji konfiguracji [`ct`](https://github.com/coreos/container-linux-config-transpiler),
    narzędzie domyślnie nie jest skompilowane na FreeBSD i musimy uruchomić je
    z Linuxa,
- `log` - standardowe wyjście uruchamianych komend,

## Procedura uruchomienia klastra

1. Wchodzę na maszynie `ldap` do folderu `/pub/Linux/CoreOS/zetis/kubernetes/kubernetes-cluster`
2. Upewniam się, że mój klucz SSH znajduje się w `boot/coreos.ign`,
3. Włączam maszyny-węzły wybierając z menu `iPXE CoreOS` -> `k8s` lub
  wybierając w narzędziu `boot` bezpośrednio `coreos kub`,
4. Upewniam się, że mam bezhasłowy dostęp do tych maszyn, minimalna
  konfiguracja `~/.ssh/config` to:
```
Host s?
  User admin
  StrictHostKeyChecking no
  UserKnownHostsFile /dev/null

Host *
  IdentityFile ~/.ssh/id_rsa
  IdentitiesOnly yes
```
 
5. Upewniam się, że istnieje folder `kubespray/my_inventory`, jeżeli nie,
  to go tworzymę kopiując domyślną konfigurację:
  ```
cp -rav kubespray/inventory kubespray/my_inventory
```

6. Otwieram plik `inventory/inventory.cfg` i upewniam się, że uruchomione
  maszyny są obecne w sekcji `[all]` oraz
  przypisane do odpowiednich ról: `[kube-master]` i `[etcd]` lub `[kube-node]`.
  Identyfikatorem maszyny jest pierwsze słowo w grupie `[all]`, przykładowa
  konfiguracja dla maszyn `s4`, `s5` i `s6` z jednym zarządcą to:
  
  ```
[all]
;s3  ip=10.146.225.3
s4  ip=10.146.225.4
s5  ip=10.146.225.5
s6  ip=10.146.225.6
;s7  ip=10.146.225.7
;s8  ip=10.146.225.8
;s9  ip=10.146.225.9
;sa  ip=10.146.225.10
;sb  ip=10.146.225.11
;sc  ip=10.146.225.12

[kube-master]
s4

[kube-node]
s5
s6

[etcd]
s4

[k8s-cluster:children]
kube-node
kube-master
```
  Opcjonalnie można do każdego węzła:
  
  - dopisać `ansible_python_interpreter=/opt/bin/python`, żeby ułatwić
    uruchamianie ansibla partiami,
  - dopisać `ansible_host=<prawdziwa_nazwa_hosta>`, jeżeli che się korzystać
    z pierwszego wyrazu opisu węzła jako aliasu, a nie faktycznej jego
    nazwy w sieci uczelnianej,
  
7. Upewniam się, że plik `inventory/group_vars/all.yml` zawiera naszą konfigurację;
  minimalny przykład:
  
  ```yaml
cluster_name: zetis-kubernetes
bootstrap_os: coreos
kube_basic_auth: true
kubeconfig_localhost: true
kubectl_localhost: true
download_run_once: true
cert_management: "{{ 'vault' if groups.get('vault', None) else 'script' }}"
helm_enabled: true
helm_deployment_type: docker
kube_script_dir: /opt/bin/kubernetes-scripts
```

8. Uruchamiam konfigurowanie maszyn `bin/setup-cluster` lub bez skryptu:
  ```bash
ldap% cd kubespray
ldap% ansible-playbook -i my_inventory/inventory.cfg cluster.yml -b -v
```
  
  Po około 10-20 minutach skrypt powinien zakończyć się wpisami pokroju:
  
  ```
...
PLAY RECAP ********
localhost                  : ok=2    changed=0    unreachable=0    failed=0   
s4                         : ok=281  changed=94   unreachable=0    failed=0   
s5                         : ok=346  changed=80   unreachable=0    failed=0   
s6                         : ok=186  changed=54   unreachable=0    failed=0   
...
```

9. Weryfikuję instalację:

```bash
ldap% bin/kubectl get nodes
NAME      STATUS    ROLES     AGE       VERSION
s4        Ready     master    2m        v1.9.1_coreos.0
s5        Ready     node      2m        v1.9.1_coreos.0
s6        Ready     node      2m        v1.9.1_coreos.0
```

## Sprawdzanie, czy klaster działa

Wywołanie skryptu `bin/students nazarewk create` jest równoważne uruchomieniu
komendy `kubectl create -f nazarewk.yml`, gdzie plik `nazarewk.yml` to:
```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: nazarewk
  labels:
    name: nazarewk
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nazarewk
  namespace: nazarewk
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: nazarewk-admin-binding
  namespace: nazarewk
roleRef:
  kind: ClusterRole
  name: admin
  apiGroup: rbac.authorization.k8s.io
subjects:
- kind: ServiceAccount
  name: nazarewk
```

W skrócie:

- tworzę `Namespace`
- tworzę `ServiceAccount`
- przypisuję wbudowaną `Role` o nazwie `admin` do `ServiceAccount` o nazwie
  `nazarewk` za pomocą `RoleBinding`,
  
#### Korzystanie z klastra jako student

- tworzę użytkownika z jego własnym `Namespace`
```
ldap% bin/students nazarewk create
namespace "nazarewk" created
serviceaccount "nazarewk" created
rolebinding "nazarewk-admin-binding" created
Tokens:
eyJhb<<<SKROCONY TOKEN>>>ahHfxU-TRw
ldap% bin/students
NAME          STATUS    AGE
default       Active    3m
kube-public   Active    3m
kube-system   Active    3m
nazarewk      Active    16s
```

- kopiuję token na `s2` z uruchomionym ubuntu:
```
  ldap% bin/student-tokens nazarewk | ssh nazarewk@s2 "cat > /tmp/token"
```

- pobieram `kubectl`
```
s2% cd /tmp
s2% curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl
s2% chmod +x kubectl
s2% sudo mv kubectl /usr/local/bin
s2% source <(kubectl completion zsh)
```

- sprawdzam, czy mam dostęp do klastra
```
s2% kubectl get nodes
The connection to the server localhost:8080 was refused - did you specify the right host or port?
```

- konfiguruję kubectl (najprościej aliasem)
```
s2% alias kubectl='command kubectl -s "https://s4:6443" --insecure-skip-tls-verify=true --token="$(cat /tmp/token)" -n nazarewk'
```

- weryfikuję brak dostępu do zasobów globalnych
```
s2% kubectl get nodes
Error from server (Forbidden): nodes is forbidden: User "system:serviceaccount:nazarewk:nazarewk" cannot list nodes at the cluster scope
```

- tworzę deployment z przykładową aplikacją
```
s2% kubectl run echoserver --image=gcr.io/google_containers/echoserver:1.4 --port=8080 --replicas=2
deployment "echoserver" created
```
```
s2% kubectl get deployments
NAME         DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
echoserver   2         2         2            2           3m
```
```
s2% kubectl get pods
NAME                         READY     STATUS    RESTARTS   AGE
echoserver-7b9bbf6ff-22df4   1/1       Running   0          4m
echoserver-7b9bbf6ff-c6kbv   1/1       Running   0          4m
```

- wystawiam port, żeby dostać się do aplikacji spoza klastra
```
s2% kubectl expose deployment echoserver --type=NodePort
service "echoserver" exposed
```
```
s2% kubectl describe services/echoserver | grep -e NodePort:
NodePort:                 <unset>  30100/TCP
```
```
s2% curl s4:30100
CLIENT VALUES:
client_address=10.233.107.64
command=GET
real path=/
query=nil
request_version=1.1
request_uri=http://s4:8080/

SERVER VALUES:
server_version=nginx: 1.10.0 - lua: 10001

HEADERS RECEIVED:
accept=*/*
host=s4:30100
user-agent=curl/7.47.0
BODY:
-no body in request-
```

- sprawdzam, czy z `ldapa` też mam dostęp do aplikacji:
```
ldap% curl s4:30100
CLIENT VALUES:
client_address=10.233.107.64
command=GET
real path=/
query=nil
request_version=1.1
request_uri=http://s4:8080/

SERVER VALUES:
server_version=nginx: 1.10.0 - lua: 10001

HEADERS RECEIVED:
accept=*/*
host=s4:30100
user-agent=curl/7.58.0
BODY:
-no body in request-
```

  - usuwam użytkownika
```
ldap% bin/students nazarewk delete
namespace "nazarewk" deleted
serviceaccount "nazarewk" deleted
rolebinding "nazarewk-admin-binding" deleted
Tokens:
Error from server (NotFound): serviceaccounts "nazarewk" not found
```

  - sprawdzam, czy coś zostało po koncie użytkownika
```
ldap% curl s4:30100
curl: (7) Failed to connect to s4 port 30100: Connection refused
```
```
ldap% bin/kubectl get namespace 
NAME          STATUS    AGE
default       Active    46m
kube-public   Active    46m
kube-system   Active    46m
```
