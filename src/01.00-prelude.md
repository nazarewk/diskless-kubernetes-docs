# Wstęp

Historia wirtualizacji i przydzielania zasobów sięga już pierwszych systemów
komputerowych.

Podstawową przeszkodą w korzystaniu z komputerów była ich wysoka
cena; bogate instytucje odpłatnie wynajmowały swoje systemy innym firmom.
Umożliwiając dostęp tylko jednemu użytkownikowi jednocześnie, maszyny przez
większość czasu nie pracowały. Wraz ze wzrostem liczby obsługiwanych
użytkowników przypadających na jedną maszynę zwiększało się wysycenie jej zasobów,
a zatem i zyski.

Następną przeszkodą okazał się brak ograniczeń dostępowych dla poszczególnych
użytkowników: każdy świadomie lub nie mógł uszkodzić cudze zasoby.
W ten sposób zrodził się pomysł `chroot`, czyli izolacji użytkowników na
poziomie systemu plików.

Wraz z rozwojem technologii zwiększała się różnorodność sprzętowa
i systemowa. W związku z pierwszą systemy operacyjne oferowały
abstrakcje dostępu do sprzętu oraz powstawały narzędzia emulujące inny sprzęt.
Różnorodność systemowa była natomiast abstrahowana przez aplikacyjne wirtualne
maszyny, które umożliwiały jednorodny dostęp do zasobów niejednorodnych
systemów operacyjnych, ale w żaden sposób go nie ograniczały.

W centrach danych zyskała popularność wirtualizacja sprzętowa. Pozwala ona
uruchomić na jednej fizycznej maszynie wiele niezależnych od
siebie maszyn wirtualnych, na których działają dowolne systemy
operacyjne. W toku rozwoju technologii po roku 2000 pojawił się trend
rozpraszania oprogramowania i dążenia do uruchamiania jak najmniejszej jego 
funkcjonalnej części na pojedynczej maszynie wirtualnej.
Główną zaletą takiego podejścia jest bezpieczeństwo: po uzyskaniu
dostępu do jednego z serwerów włamywacz nadal nie ma dostępu do reszty
infrastruktury.
Wadą natomiast jest to, że jedna maszyna fizyczna jest w stanie uruchomić nie
więcej niż kilka do kilkunastu maszyn wirtualnych.
W związku z tym utrzymywanie całej maszyny wirtualnej w celu uruchamiania
pojedynczego procesu aplikacyjnego często jest nieekonomiczne.

Na przełomie ostatniej dekady zaczęły pojawiać się narzędzia pozwalające
uruchamiać wiele w pełni odizolowanych procesów współdzielących jedynie jądro
systemu operacyjnego.
Znacznie zmniejszyło to narzut zasobów wymaganych do uruchamiania kolejnych
aplikacji-procesów i umożliwiło współdzielenie jednej maszyny przez setki,
a nawet tysiące programów.
Metodologia ta zyskała miano konteneryzacji i jest z powodzeniem wykorzystywana
w systemach produkcyjnych na całym świecie.

Technologia konteneryzacji jest młoda, a konkurencja duża. Z jednej strony trwa
wyścig o stworzenie najlepszego rozwiązania, a z drugiej aktywnie rozwijane są 
otwarte standardy konteneryzacji w ramach [`Open Container Initiative`](https://www.opencontainers.org/about),
ponieważ nikt nie może pozwolić sobie na niekompatybilność swojej implementacji.
Obecnie najpopularniejszą implementacją kontenerów jest `Docker`.

Aspektem równie ważnym jak sama implementacja kontenerów, jest kwestia zarządzania nimi.
O ile kilkoma serwerami z kilkudziesięcioma kontenerami może zarządzać człowiek,
o tyle do zarządzania tysiącami kontenerów wymagany jest w dużej mierze
zautomatyzowany i wyspecjalizowany system.

Obecnie przodującym rozwiązaniem tego problemu jest `Kubernetes` (zamiennie
`k8s`). Projekt powstał niedawno (w połowie 2014 roku) i mimo tego, że coraz
bardziej umacnia swoją pozycję na rynku nadal umie go skonfigurować tylko
nieliczne grono specjalistów. Celem niniejszej pracy jest przedstawienie
sposobu konfiguracji klastra `k8s` na fizycznych maszynach^[ang. _bare metal_,
czyli uruchamianie na prostej sieci komputerowej bez zewnętrznych zależności,
w odróżnieniu od kompleksowych usług chmurowych, które w znacznym stopniu
automatyzują i ułatwiają konfigurację]
na przykładzie sieci komputerowej Wydziału Elektrycznego Politechniki Warszawskiej.
Laboratoria komputerowe dostępne w tej sieci są wyposażone w maszyny bezdyskowe,
a zatem należy pokrótce scharakteryzować tego typu systemy.


## Charakterystyka systemów bezdyskowych

W dzisiejszych czasach rozwój sieci komputerowych i spadek cen pamięci RAM
pozwolił na konfigurację maszyn nie posiadających dysku twardego.
Bezdyskowe maszyny przy starcie pytają centralny serwer o swoją konfigurację
(np. protokołem `PXE`), a następnie umieszczają kompletny system operacyjny
w pamięci RAM.

W momencie wyłączenia maszyny cały stan jest tracony, a przy ponownym rozruchu
konfigurowana jest od nowa.
w celu trwałego przechowywania danych systemy bezdyskowe korzystają z
zewnętrznych serwerów plikowych.

Rozwiązanie pozwala to na jednorazową konfigurację bazowego systemu operacyjnego
i uzyskanie konfiguracji na dowolnej ilości maszyn bez ingerencji człowieka.
W efekcie koszt utrzymania centrów danych przenosi się z konfiguracji
indywidualnych maszyn na konfigurację pojedynczych usług działających na
dowolnej liczbie maszyn.

Zarządzanie klastrem `k8s` poza środowiskiem chmurowym znacznie ogranicza
wybór narzędzia konfiguracyjnego, a bezdyskowość jego węzłów ma duży wpływ
na wybór systemu operacyjnego.
